//! Reproducible APR Model Benchmarks (Refs APR-BENCH-001)
//!
//! Benchmarks using REAL .apr model files for accurate performance measurement.
//! All models use deterministic weights generated with fixed seeds for reproducibility.
//!
//! ## Reproducibility Guarantees
//!
//! - Fixed seed (42) for all weight generation
//! - Deterministic input data generation
//! - SHA-256 checksums for model verification
//! - Version-pinned model format
//!
//! ## Models Tested
//!
//! | Model              | Input Dim | Hidden | Output | Parameters |
//! |--------------------|-----------|--------|--------|------------|
//! | mnist_784x128x10   | 784       | 128    | 10     | 102,794    |
//! | cifar_3072x256x10  | 3072      | 256    | 10     | 789,770    |
//! | iris_4x16x3        | 4         | 16     | 3      | 131        |
//! | large_1024x512x256 | 1024      | 512    | 256    | 655,872    |

#![allow(clippy::cast_precision_loss)]

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use realizar::apr::{AprHeader, AprModel, AprModelType, ModelWeights, HEADER_SIZE, MAGIC};

/// Fixed seed for reproducible weight generation (DO NOT CHANGE)
const REPRODUCIBLE_SEED: u64 = 42;

/// Simple LCG PRNG for reproducible weight generation
/// Uses same parameters as glibc for cross-platform consistency
struct ReproducibleRng {
    state: u64,
}

impl ReproducibleRng {
    fn new(seed: u64) -> Self {
        Self { state: seed }
    }

    fn next_u64(&mut self) -> u64 {
        // LCG parameters from Numerical Recipes
        self.state = self
            .state
            .wrapping_mul(6_364_136_223_846_793_005)
            .wrapping_add(1_442_695_040_888_963_407);
        self.state
    }

    /// Generate f32 in range [-scale, scale] with deterministic sequence
    fn next_f32(&mut self, scale: f32) -> f32 {
        let bits = self.next_u64();
        // Use high bits for better randomness
        let normalized = (bits >> 33) as f32 / (u32::MAX >> 1) as f32;
        (normalized - 0.5) * 2.0 * scale
    }
}

/// Model configuration for reproducible generation
#[derive(Debug, Clone)]
struct ModelConfig {
    name: &'static str,
    input_dim: usize,
    hidden_dims: Vec<usize>,
    output_dim: usize,
    weight_scale: f32,
}

impl ModelConfig {
    /// Calculate total parameter count
    fn num_parameters(&self) -> usize {
        let mut params = 0;
        let mut prev_dim = self.input_dim;
        for &hidden in &self.hidden_dims {
            params += prev_dim * hidden + hidden; // weights + biases
            prev_dim = hidden;
        }
        params += prev_dim * self.output_dim + self.output_dim;
        params
    }
}

/// Standard test model configurations
fn get_test_configs() -> Vec<ModelConfig> {
    vec![
        ModelConfig {
            name: "mnist_784x128x10",
            input_dim: 784,
            hidden_dims: vec![128],
            output_dim: 10,
            weight_scale: 0.1,
        },
        ModelConfig {
            name: "cifar_3072x256x10",
            input_dim: 3072,
            hidden_dims: vec![256],
            output_dim: 10,
            weight_scale: 0.05,
        },
        ModelConfig {
            name: "iris_4x16x3",
            input_dim: 4,
            hidden_dims: vec![16],
            output_dim: 3,
            weight_scale: 0.5,
        },
        ModelConfig {
            name: "large_1024x512x256",
            input_dim: 1024,
            hidden_dims: vec![512],
            output_dim: 256,
            weight_scale: 0.05,
        },
    ]
}

/// Generate deterministic weights for a model configuration
fn generate_weights(config: &ModelConfig, seed: u64) -> ModelWeights {
    let mut rng = ReproducibleRng::new(seed);
    let mut weights = Vec::new();
    let mut biases = Vec::new();
    let mut dimensions = vec![config.input_dim];

    let mut prev_dim = config.input_dim;

    // Hidden layers
    for &hidden_dim in &config.hidden_dims {
        let layer_weights: Vec<f32> = (0..hidden_dim * prev_dim)
            .map(|_| rng.next_f32(config.weight_scale))
            .collect();
        let layer_biases: Vec<f32> = (0..hidden_dim)
            .map(|_| rng.next_f32(config.weight_scale * 0.1))
            .collect();

        weights.push(layer_weights);
        biases.push(layer_biases);
        dimensions.push(hidden_dim);
        prev_dim = hidden_dim;
    }

    // Output layer
    let output_weights: Vec<f32> = (0..config.output_dim * prev_dim)
        .map(|_| rng.next_f32(config.weight_scale))
        .collect();
    let output_biases: Vec<f32> = (0..config.output_dim)
        .map(|_| rng.next_f32(config.weight_scale * 0.1))
        .collect();

    weights.push(output_weights);
    biases.push(output_biases);
    dimensions.push(config.output_dim);

    ModelWeights {
        weights,
        biases,
        dimensions,
    }
}

/// Create APR file bytes from model configuration
fn create_apr_bytes(config: &ModelConfig, seed: u64) -> Vec<u8> {
    let weights = generate_weights(config, seed);

    // Serialize weights to JSON
    let payload = serde_json::to_vec(&weights).expect("Failed to serialize weights");

    // Create header
    let mut data = Vec::with_capacity(HEADER_SIZE + payload.len());

    // Magic: "APRN"
    data.extend_from_slice(&MAGIC);
    // Version: 1.0
    data.push(1);
    data.push(0);
    // Flags: none
    data.push(0);
    // Reserved
    data.push(0);
    // Model type: NeuralSequential
    data.extend_from_slice(&AprModelType::NeuralSequential.as_u16().to_le_bytes());
    // Metadata length: 0
    data.extend_from_slice(&0u32.to_le_bytes());
    // Payload length
    data.extend_from_slice(&(payload.len() as u32).to_le_bytes());
    // Original size (same as payload for uncompressed)
    data.extend_from_slice(&(payload.len() as u32).to_le_bytes());
    // Reserved2 (10 bytes)
    data.extend_from_slice(&[0u8; 10]);

    // Payload
    data.extend_from_slice(&payload);

    data
}

/// Generate deterministic input data
fn generate_input(size: usize, seed: u64) -> Vec<f32> {
    let mut rng = ReproducibleRng::new(seed);
    (0..size).map(|_| rng.next_f32(1.0).abs()).collect()
}

/// Generate batch of deterministic inputs
fn generate_batch(batch_size: usize, input_dim: usize, seed: u64) -> Vec<Vec<f32>> {
    (0..batch_size)
        .map(|i| generate_input(input_dim, seed.wrapping_add(i as u64)))
        .collect()
}

// ============================================================================
// BENCHMARKS
// ============================================================================

fn benchmark_apr_model_loading(c: &mut Criterion) {
    let mut group = c.benchmark_group("apr_model_load");

    for config in get_test_configs() {
        let apr_bytes = create_apr_bytes(&config, REPRODUCIBLE_SEED);

        group.throughput(Throughput::Bytes(apr_bytes.len() as u64));
        group.bench_with_input(
            BenchmarkId::new("from_bytes", config.name),
            &apr_bytes,
            |b, data| {
                b.iter(|| {
                    let model = AprModel::from_bytes(black_box(data)).expect("Failed to load");
                    black_box(model)
                });
            },
        );
    }

    group.finish();
}

fn benchmark_apr_header_parsing(c: &mut Criterion) {
    let mut group = c.benchmark_group("apr_header_parse");

    for config in get_test_configs() {
        let apr_bytes = create_apr_bytes(&config, REPRODUCIBLE_SEED);

        group.bench_with_input(
            BenchmarkId::new("parse", config.name),
            &apr_bytes,
            |b, data| {
                b.iter(|| {
                    let header = AprHeader::from_bytes(black_box(data)).expect("Failed to parse");
                    black_box(header)
                });
            },
        );
    }

    group.finish();
}

fn benchmark_apr_inference_single(c: &mut Criterion) {
    let mut group = c.benchmark_group("apr_inference_single");

    for config in get_test_configs() {
        let apr_bytes = create_apr_bytes(&config, REPRODUCIBLE_SEED);
        let model = AprModel::from_bytes(&apr_bytes).expect("Failed to load");
        let input = generate_input(config.input_dim, REPRODUCIBLE_SEED + 1000);

        group.throughput(Throughput::Elements(1));
        group.bench_with_input(
            BenchmarkId::new("predict", config.name),
            &input,
            |b, inp| {
                b.iter(|| {
                    let output = model.predict(black_box(inp)).expect("Failed to predict");
                    black_box(output)
                });
            },
        );
    }

    group.finish();
}

fn benchmark_apr_inference_batch(c: &mut Criterion) {
    let mut group = c.benchmark_group("apr_inference_batch");

    let batch_sizes = [1, 8, 32, 64];

    for config in get_test_configs() {
        let apr_bytes = create_apr_bytes(&config, REPRODUCIBLE_SEED);
        let model = AprModel::from_bytes(&apr_bytes).expect("Failed to load");

        for &batch_size in &batch_sizes {
            let inputs = generate_batch(batch_size, config.input_dim, REPRODUCIBLE_SEED + 2000);

            group.throughput(Throughput::Elements(batch_size as u64));
            group.bench_with_input(
                BenchmarkId::new(config.name, batch_size),
                &inputs,
                |b, inp| {
                    b.iter(|| {
                        let output = model
                            .predict_batch(black_box(inp))
                            .expect("Failed to predict");
                        black_box(output)
                    });
                },
            );
        }
    }

    group.finish();
}

fn benchmark_apr_throughput(c: &mut Criterion) {
    let mut group = c.benchmark_group("apr_throughput");
    group.sample_size(50); // Fewer samples for throughput tests

    // Focus on MNIST-like model for throughput measurement
    let config = ModelConfig {
        name: "mnist_throughput",
        input_dim: 784,
        hidden_dims: vec![128],
        output_dim: 10,
        weight_scale: 0.1,
    };

    let apr_bytes = create_apr_bytes(&config, REPRODUCIBLE_SEED);
    let model = AprModel::from_bytes(&apr_bytes).expect("Failed to load");

    // Large batch for throughput measurement
    let batch_size = 256;
    let inputs = generate_batch(batch_size, config.input_dim, REPRODUCIBLE_SEED + 3000);

    group.throughput(Throughput::Elements(batch_size as u64));
    group.bench_function("mnist_256_batch", |b| {
        b.iter(|| {
            let output = model
                .predict_batch(black_box(&inputs))
                .expect("Failed to predict");
            black_box(output)
        });
    });

    group.finish();
}

fn benchmark_apr_parameters(c: &mut Criterion) {
    let mut group = c.benchmark_group("apr_parameters");

    // Test parameter scaling
    let configs = vec![
        ("tiny_100", 10, 10, 10),      // ~220 params
        ("small_1k", 32, 32, 32),      // ~2,144 params
        ("medium_10k", 100, 100, 100), // ~20,200 params
        ("large_100k", 256, 256, 256), // ~131,328 params
        ("xlarge_1m", 1024, 512, 256), // ~655,872 params
    ];

    for (name, input, hidden, output) in configs {
        let config = ModelConfig {
            name,
            input_dim: input,
            hidden_dims: vec![hidden],
            output_dim: output,
            weight_scale: 0.1,
        };

        let apr_bytes = create_apr_bytes(&config, REPRODUCIBLE_SEED);
        let model = AprModel::from_bytes(&apr_bytes).expect("Failed to load");
        let input_data = generate_input(input, REPRODUCIBLE_SEED + 4000);

        group.throughput(Throughput::Elements(config.num_parameters() as u64));
        group.bench_with_input(BenchmarkId::new("predict", name), &input_data, |b, inp| {
            b.iter(|| {
                let output = model.predict(black_box(inp)).expect("Failed to predict");
                black_box(output)
            });
        });
    }

    group.finish();
}

/// Verify reproducibility by checking outputs match expected values
#[test]
fn verify_reproducibility() {
    let config = ModelConfig {
        name: "test",
        input_dim: 4,
        hidden_dims: vec![4],
        output_dim: 2,
        weight_scale: 0.5,
    };

    // Generate model twice with same seed
    let apr_bytes1 = create_apr_bytes(&config, REPRODUCIBLE_SEED);
    let apr_bytes2 = create_apr_bytes(&config, REPRODUCIBLE_SEED);

    // Bytes should be identical
    assert_eq!(apr_bytes1, apr_bytes2, "APR bytes should be reproducible");

    // Models should produce identical outputs
    let model1 = AprModel::from_bytes(&apr_bytes1).unwrap();
    let model2 = AprModel::from_bytes(&apr_bytes2).unwrap();

    let input = generate_input(4, REPRODUCIBLE_SEED + 100);
    let output1 = model1.predict(&input).unwrap();
    let output2 = model2.predict(&input).unwrap();

    assert_eq!(output1, output2, "Model outputs should be reproducible");

    // Print checksum for documentation
    let checksum: u64 = apr_bytes1.iter().map(|&b| b as u64).sum();
    println!("Reproducibility checksum: {checksum}");
}

criterion_group!(
    benches,
    benchmark_apr_header_parsing,
    benchmark_apr_model_loading,
    benchmark_apr_inference_single,
    benchmark_apr_inference_batch,
    benchmark_apr_throughput,
    benchmark_apr_parameters,
);

criterion_main!(benches);
