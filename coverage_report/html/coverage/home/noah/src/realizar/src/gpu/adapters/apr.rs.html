<!doctype html><html><head><meta name='viewport' content='width=device-width,initial-scale=1'><meta charset='UTF-8'><link rel='stylesheet' type='text/css' href='../../../../../../../../style.css'><script src='../../../../../../../../control.js'></script></head><body><h2>Coverage Report</h2><h4>Created: 2026-01-25 15:05</h4><span class='control'><a href='javascript:next_line()'>next uncovered line (L)</a>, <a href='javascript:next_region()'>next uncovered region (R)</a>, <a href='javascript:next_branch()'>next uncovered branch (B)</a></span><div class='centered'><table><div class='source-name-title'><pre>/home/noah/src/realizar/src/gpu/adapters/apr.rs</pre></div><tr><td><pre>Line</pre></td><td><pre>Count</pre></td><td><pre>Source</pre></td></tr><tr><td class='line-number'><a name='L1' href='#L1'><pre>1</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! APR to GpuModel Adapter (PMAT-106)</pre></td></tr><tr><td class='line-number'><a name='L2' href='#L2'><pre>2</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//!</pre></td></tr><tr><td class='line-number'><a name='L3' href='#L3'><pre>3</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! Converts APR transformers to `GpuModel` for GPU inference.</pre></td></tr><tr><td class='line-number'><a name='L4' href='#L4'><pre>4</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//!</pre></td></tr><tr><td class='line-number'><a name='L5' href='#L5'><pre>5</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! # Overview</pre></td></tr><tr><td class='line-number'><a name='L6' href='#L6'><pre>6</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//!</pre></td></tr><tr><td class='line-number'><a name='L7' href='#L7'><pre>7</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! This module provides adapters for both F32 and Q4 APR formats:</pre></td></tr><tr><td class='line-number'><a name='L8' href='#L8'><pre>8</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! - [`AprF32ToGpuAdapter`] - For `.apr` files with F32 weights (direct copy)</pre></td></tr><tr><td class='line-number'><a name='L9' href='#L9'><pre>9</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! - [`AprToGpuAdapter`] - For GGUF Q4_0 models (dequantizes to F32)</pre></td></tr><tr><td class='line-number'><a name='L10' href='#L10'><pre>10</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//!</pre></td></tr><tr><td class='line-number'><a name='L11' href='#L11'><pre>11</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! # Coverage Impact</pre></td></tr><tr><td class='line-number'><a name='L12' href='#L12'><pre>12</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//!</pre></td></tr><tr><td class='line-number'><a name='L13' href='#L13'><pre>13</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! Testing these adapters exercises:</pre></td></tr><tr><td class='line-number'><a name='L14' href='#L14'><pre>14</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! - `apr_transformer/mod.rs` - F32 weight extraction</pre></td></tr><tr><td class='line-number'><a name='L15' href='#L15'><pre>15</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! - `apr_transformer/q4_simd.rs` - Q4 weight extraction</pre></td></tr><tr><td class='line-number'><a name='L16' href='#L16'><pre>16</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! - `gpu/scheduler/model.rs` - GpuModel creation</pre></td></tr><tr><td class='line-number'><a name='L17' href='#L17'><pre>17</pre></a></td><td class='skipped-line'></td><td class='code'><pre>//! - `quantize/dequant.rs` - Q4_0 dequantization</pre></td></tr><tr><td class='line-number'><a name='L18' href='#L18'><pre>18</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L19' href='#L19'><pre>19</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::apr_transformer::{</pre></td></tr><tr><td class='line-number'><a name='L20' href='#L20'><pre>20</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    AprTransformer, AprTransformerConfig, AprTransformerLayer,</pre></td></tr><tr><td class='line-number'><a name='L21' href='#L21'><pre>21</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    QuantizedAprTransformerQ4, QuantizedAprLayerQ4,</pre></td></tr><tr><td class='line-number'><a name='L22' href='#L22'><pre>22</pre></a></td><td class='skipped-line'></td><td class='code'><pre>};</pre></td></tr><tr><td class='line-number'><a name='L23' href='#L23'><pre>23</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::gpu::scheduler::{GpuModel, GpuModelConfig, BlockWeights};</pre></td></tr><tr><td class='line-number'><a name='L24' href='#L24'><pre>24</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::quantize::dequantize_q4_0;</pre></td></tr><tr><td class='line-number'><a name='L25' href='#L25'><pre>25</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use crate::error::Result;</pre></td></tr><tr><td class='line-number'><a name='L26' href='#L26'><pre>26</pre></a></td><td class='skipped-line'></td><td class='code'><pre>use thiserror::Error;</pre></td></tr><tr><td class='line-number'><a name='L27' href='#L27'><pre>27</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L28' href='#L28'><pre>28</pre></a></td><td class='skipped-line'></td><td class='code'><pre>/// Errors during APR to GPU conversion</pre></td></tr><tr><td class='line-number'><a name='L29' href='#L29'><pre>29</pre></a></td><td class='skipped-line'></td><td class='code'><pre>#[derive(Debug, Error)]</pre></td></tr><tr><td class='line-number'><a name='L30' href='#L30'><pre>30</pre></a></td><td class='skipped-line'></td><td class='code'><pre>pub enum AprGpuError {</pre></td></tr><tr><td class='line-number'><a name='L31' href='#L31'><pre>31</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Dequantization failed</pre></td></tr><tr><td class='line-number'><a name='L32' href='#L32'><pre>32</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    #[error(&quot;Failed to dequantize Q4_0 weights: {0}&quot;)]</pre></td></tr><tr><td class='line-number'><a name='L33' href='#L33'><pre>33</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    DequantError(String),</pre></td></tr><tr><td class='line-number'><a name='L34' href='#L34'><pre>34</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L35' href='#L35'><pre>35</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Weight dimension mismatch</pre></td></tr><tr><td class='line-number'><a name='L36' href='#L36'><pre>36</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    #[error(&quot;Weight dimension mismatch: expected {expected}, got {actual}&quot;)]</pre></td></tr><tr><td class='line-number'><a name='L37' href='#L37'><pre>37</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    DimensionMismatch {</pre></td></tr><tr><td class='line-number'><a name='L38' href='#L38'><pre>38</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        /// Expected number of elements</pre></td></tr><tr><td class='line-number'><a name='L39' href='#L39'><pre>39</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        expected: usize,</pre></td></tr><tr><td class='line-number'><a name='L40' href='#L40'><pre>40</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        /// Actual number of elements</pre></td></tr><tr><td class='line-number'><a name='L41' href='#L41'><pre>41</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        actual: usize,</pre></td></tr><tr><td class='line-number'><a name='L42' href='#L42'><pre>42</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    },</pre></td></tr><tr><td class='line-number'><a name='L43' href='#L43'><pre>43</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L44' href='#L44'><pre>44</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// GpuModel creation failed</pre></td></tr><tr><td class='line-number'><a name='L45' href='#L45'><pre>45</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    #[error(&quot;Failed to create GpuModel: {0}&quot;)]</pre></td></tr><tr><td class='line-number'><a name='L46' href='#L46'><pre>46</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    GpuModelError(String),</pre></td></tr><tr><td class='line-number'><a name='L47' href='#L47'><pre>47</pre></a></td><td class='skipped-line'></td><td class='code'><pre>}</pre></td></tr><tr><td class='line-number'><a name='L48' href='#L48'><pre>48</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L49' href='#L49'><pre>49</pre></a></td><td class='skipped-line'></td><td class='code'><pre>/// Adapter for converting F32 APR models to GPU format</pre></td></tr><tr><td class='line-number'><a name='L50' href='#L50'><pre>50</pre></a></td><td class='skipped-line'></td><td class='code'><pre>///</pre></td></tr><tr><td class='line-number'><a name='L51' href='#L51'><pre>51</pre></a></td><td class='skipped-line'></td><td class='code'><pre>/// Used for `.apr` files which contain F32 weights. No dequantization needed.</pre></td></tr><tr><td class='line-number'><a name='L52' href='#L52'><pre>52</pre></a></td><td class='skipped-line'></td><td class='code'><pre>pub struct AprF32ToGpuAdapter;</pre></td></tr><tr><td class='line-number'><a name='L53' href='#L53'><pre>53</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L54' href='#L54'><pre>54</pre></a></td><td class='skipped-line'></td><td class='code'><pre>impl AprF32ToGpuAdapter {</pre></td></tr><tr><td class='line-number'><a name='L55' href='#L55'><pre>55</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Convert F32 APR transformer to GpuModel</pre></td></tr><tr><td class='line-number'><a name='L56' href='#L56'><pre>56</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L57' href='#L57'><pre>57</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Arguments</pre></td></tr><tr><td class='line-number'><a name='L58' href='#L58'><pre>58</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L59' href='#L59'><pre>59</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// * `apr` - Source APR transformer with F32 weights</pre></td></tr><tr><td class='line-number'><a name='L60' href='#L60'><pre>60</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L61' href='#L61'><pre>61</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Returns</pre></td></tr><tr><td class='line-number'><a name='L62' href='#L62'><pre>62</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L63' href='#L63'><pre>63</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// `GpuModel` ready for GPU inference</pre></td></tr><tr><td class='line-number'><a name='L64' href='#L64'><pre>64</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L65' href='#L65'><pre>65</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Example</pre></td></tr><tr><td class='line-number'><a name='L66' href='#L66'><pre>66</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L67' href='#L67'><pre>67</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// ```ignore</pre></td></tr><tr><td class='line-number'><a name='L68' href='#L68'><pre>68</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// use realizar::apr_transformer::AprTransformer;</pre></td></tr><tr><td class='line-number'><a name='L69' href='#L69'><pre>69</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// use realizar::gpu::adapters::AprF32ToGpuAdapter;</pre></td></tr><tr><td class='line-number'><a name='L70' href='#L70'><pre>70</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L71' href='#L71'><pre>71</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// let apr = AprTransformer::from_apr_bytes(&amp;data)?;</pre></td></tr><tr><td class='line-number'><a name='L72' href='#L72'><pre>72</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// let gpu_model = AprF32ToGpuAdapter::to_gpu_model(&amp;apr)?;</pre></td></tr><tr><td class='line-number'><a name='L73' href='#L73'><pre>73</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// ```</pre></td></tr><tr><td class='line-number'><a name='L74' href='#L74'><pre>74</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>pub fn to_gpu_model(apr: &amp;AprTransformer) -&gt; Result&lt;GpuModel&gt;</span> {</pre></td></tr><tr><td class='line-number'><a name='L75' href='#L75'><pre>75</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>config</span> = <span class='region red'>AprToGpuAdapter::config_to_gpu</span>(<span class='region red'>&amp;apr.config</span>);</pre></td></tr><tr><td class='line-number'><a name='L76' href='#L76'><pre>76</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>hidden_dim</span> = <span class='region red'>config.hidden_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L77' href='#L77'><pre>77</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>intermediate_dim</span> = <span class='region red'>config.intermediate_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L78' href='#L78'><pre>78</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L79' href='#L79'><pre>79</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Embedding weights (already F32)</pre></td></tr><tr><td class='line-number'><a name='L80' href='#L80'><pre>80</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>embedding_weights</span> = <span class='region red'>apr.token_embedding</span>.<span class='region red'>clone</span>();</pre></td></tr><tr><td class='line-number'><a name='L81' href='#L81'><pre>81</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L82' href='#L82'><pre>82</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // LM head weights (already F32)</pre></td></tr><tr><td class='line-number'><a name='L83' href='#L83'><pre>83</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>lm_head_weight</span> = <span class='region red'>apr.lm_head_weight</span>.<span class='region red'>clone</span>();</pre></td></tr><tr><td class='line-number'><a name='L84' href='#L84'><pre>84</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L85' href='#L85'><pre>85</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Phase 22 FIX: Transpose LM head from APR [vocab_size, hidden_dim] to GPU [hidden_dim, vocab_size]</pre></td></tr><tr><td class='line-number'><a name='L86' href='#L86'><pre>86</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // APR stores weights as [out_dim, in_dim], GPU matmul expects [in_dim, out_dim]</pre></td></tr><tr><td class='line-number'><a name='L87' href='#L87'><pre>87</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>lm_head_weight_t</span> = <span class='region red'>transpose_matrix</span>(<span class='region red'>&amp;lm_head_weight</span>, <span class='region red'>config.vocab_size</span>, <span class='region red'>hidden_dim</span>);</pre></td></tr><tr><td class='line-number'><a name='L88' href='#L88'><pre>88</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L89' href='#L89'><pre>89</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Convert each layer</pre></td></tr><tr><td class='line-number'><a name='L90' href='#L90'><pre>90</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>mut block_weights</span> = <span class='region red'>Vec::with_capacity</span>(<span class='region red'>apr.layers</span>.<span class='region red'>len</span>());</pre></td></tr><tr><td class='line-number'><a name='L91' href='#L91'><pre>91</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        for <span class='region red'>layer</span> in <span class='region red'>&amp;apr.layers</span> <span class='region red'>{</span></pre></td></tr><tr><td class='line-number'><a name='L92' href='#L92'><pre>92</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>            </span><span class='region red'>block_weights</span><span class='region red'>.</span><span class='region red'>push</span><span class='region red'>(</span><span class='region red'>Self::convert_layer</span><span class='region red'>(</span></pre></td></tr><tr><td class='line-number'><a name='L93' href='#L93'><pre>93</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>                </span><span class='region red'>layer</span><span class='region red'>,</span></pre></td></tr><tr><td class='line-number'><a name='L94' href='#L94'><pre>94</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>                </span><span class='region red'>hidden_dim</span><span class='region red'>,</span></pre></td></tr><tr><td class='line-number'><a name='L95' href='#L95'><pre>95</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>                </span><span class='region red'>intermediate_dim</span><span class='region red'>,</span></pre></td></tr><tr><td class='line-number'><a name='L96' href='#L96'><pre>96</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>                config.num_heads,</span></pre></td></tr><tr><td class='line-number'><a name='L97' href='#L97'><pre>97</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>                config.num_kv_heads,</span></pre></td></tr><tr><td class='line-number'><a name='L98' href='#L98'><pre>98</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>            ));</span></pre></td></tr><tr><td class='line-number'><a name='L99' href='#L99'><pre>99</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        }</span></pre></td></tr><tr><td class='line-number'><a name='L100' href='#L100'><pre>100</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L101' href='#L101'><pre>101</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Final norm</pre></td></tr><tr><td class='line-number'><a name='L102' href='#L102'><pre>102</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>final_norm_weight</span> = <span class='region red'>apr.output_norm_weight</span>.<span class='region red'>clone</span>();</pre></td></tr><tr><td class='line-number'><a name='L103' href='#L103'><pre>103</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>final_norm_bias</span> = <span class='region red'>apr.output_norm_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>]);</pre></td></tr><tr><td class='line-number'><a name='L104' href='#L104'><pre>104</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L105' href='#L105'><pre>105</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // LM head bias</pre></td></tr><tr><td class='line-number'><a name='L106' href='#L106'><pre>106</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>lm_head_bias</span> = <span class='region red'>apr.lm_head_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[0.0; <span class='region red'>config.vocab_size</span>]);</pre></td></tr><tr><td class='line-number'><a name='L107' href='#L107'><pre>107</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L108' href='#L108'><pre>108</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Create GpuModel using internal constructor</pre></td></tr><tr><td class='line-number'><a name='L109' href='#L109'><pre>109</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        <span class='region red'>GpuModel::from_apr_weights</span>(</pre></td></tr><tr><td class='line-number'><a name='L110' href='#L110'><pre>110</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>config</span>,</pre></td></tr><tr><td class='line-number'><a name='L111' href='#L111'><pre>111</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>embedding_weights</span>,</pre></td></tr><tr><td class='line-number'><a name='L112' href='#L112'><pre>112</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>block_weights</span>,</pre></td></tr><tr><td class='line-number'><a name='L113' href='#L113'><pre>113</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>final_norm_weight</span>,</pre></td></tr><tr><td class='line-number'><a name='L114' href='#L114'><pre>114</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>final_norm_bias</span>,</pre></td></tr><tr><td class='line-number'><a name='L115' href='#L115'><pre>115</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>lm_head_weight</span>,</pre></td></tr><tr><td class='line-number'><a name='L116' href='#L116'><pre>116</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>lm_head_weight_t</span>,</pre></td></tr><tr><td class='line-number'><a name='L117' href='#L117'><pre>117</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>lm_head_bias</span>,</pre></td></tr><tr><td class='line-number'><a name='L118' href='#L118'><pre>118</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        )</pre></td></tr><tr><td class='line-number'><a name='L119' href='#L119'><pre>119</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>}</span></pre></td></tr><tr><td class='line-number'><a name='L120' href='#L120'><pre>120</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L121' href='#L121'><pre>121</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Convert a single F32 layer to BlockWeights</pre></td></tr><tr><td class='line-number'><a name='L122' href='#L122'><pre>122</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>fn convert_layer(</span></pre></td></tr><tr><td class='line-number'><a name='L123' href='#L123'><pre>123</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        layer: &amp;AprTransformerLayer,</span></pre></td></tr><tr><td class='line-number'><a name='L124' href='#L124'><pre>124</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        hidden_dim: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L125' href='#L125'><pre>125</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        intermediate_dim: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L126' href='#L126'><pre>126</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        num_heads: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L127' href='#L127'><pre>127</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        num_kv_heads: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L128' href='#L128'><pre>128</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>    ) -&gt; BlockWeights</span> {</pre></td></tr><tr><td class='line-number'><a name='L129' href='#L129'><pre>129</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Phase 21 FIX: APR stores weights as [out_dim, in_dim] row-major,</pre></td></tr><tr><td class='line-number'><a name='L130' href='#L130'><pre>130</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // but GPU gemm expects [in_dim, out_dim]. Transpose all projection weights.</pre></td></tr><tr><td class='line-number'><a name='L131' href='#L131'><pre>131</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>head_dim</span> = <span class='region red'>hidden_dim / num_heads</span>;</pre></td></tr><tr><td class='line-number'><a name='L132' href='#L132'><pre>132</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>kv_dim</span> = <span class='region red'>num_kv_heads * head_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L133' href='#L133'><pre>133</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>qkv_out_dim</span> = <span class='region red'>hidden_dim + 2 * kv_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L134' href='#L134'><pre>134</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L135' href='#L135'><pre>135</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Transpose QKV: [qkv_out_dim, hidden_dim] -&gt; [hidden_dim, qkv_out_dim]</pre></td></tr><tr><td class='line-number'><a name='L136' href='#L136'><pre>136</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>qkv_weight_t</span> = <span class='region red'>transpose_matrix</span>(<span class='region red'>&amp;layer.qkv_weight</span>, <span class='region red'>qkv_out_dim</span>, <span class='region red'>hidden_dim</span>);</pre></td></tr><tr><td class='line-number'><a name='L137' href='#L137'><pre>137</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L138' href='#L138'><pre>138</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Transpose output projection: [hidden_dim, hidden_dim] -&gt; [hidden_dim, hidden_dim]</pre></td></tr><tr><td class='line-number'><a name='L139' href='#L139'><pre>139</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>out_weight_t</span> = <span class='region red'>transpose_matrix</span>(<span class='region red'>&amp;layer.attn_output_weight</span>, <span class='region red'>hidden_dim</span>, <span class='region red'>hidden_dim</span>);</pre></td></tr><tr><td class='line-number'><a name='L140' href='#L140'><pre>140</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L141' href='#L141'><pre>141</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Transpose FFN up (fc1): [intermediate_dim, hidden_dim] -&gt; [hidden_dim, intermediate_dim]</pre></td></tr><tr><td class='line-number'><a name='L142' href='#L142'><pre>142</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>fc1_weight_t</span> = <span class='region red'>transpose_matrix</span>(<span class='region red'>&amp;layer.ffn_up_weight</span>, <span class='region red'>intermediate_dim</span>, <span class='region red'>hidden_dim</span>);</pre></td></tr><tr><td class='line-number'><a name='L143' href='#L143'><pre>143</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L144' href='#L144'><pre>144</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Transpose FFN down (fc2): [hidden_dim, intermediate_dim] -&gt; [intermediate_dim, hidden_dim]</pre></td></tr><tr><td class='line-number'><a name='L145' href='#L145'><pre>145</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>fc2_weight_t</span> = <span class='region red'>transpose_matrix</span>(<span class='region red'>&amp;layer.ffn_down_weight</span>, <span class='region red'>hidden_dim</span>, <span class='region red'>intermediate_dim</span>);</pre></td></tr><tr><td class='line-number'><a name='L146' href='#L146'><pre>146</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L147' href='#L147'><pre>147</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Transpose gate weight if present: [intermediate_dim, hidden_dim] -&gt; [hidden_dim, intermediate_dim]</pre></td></tr><tr><td class='line-number'><a name='L148' href='#L148'><pre>148</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>gate_weight_t</span> = <span class='region red'>layer.ffn_gate_weight</span>.<span class='region red'>as_ref</span>().<span class='region red'>map</span>(|w| <span class='region red'>{</span></pre></td></tr><tr><td class='line-number'><a name='L149' href='#L149'><pre>149</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>transpose_matrix</span>(<span class='region red'>w</span>, <span class='region red'>intermediate_dim</span>, <span class='region red'>hidden_dim</span>)</pre></td></tr><tr><td class='line-number'><a name='L150' href='#L150'><pre>150</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        <span class='region red'>}</span>);</pre></td></tr><tr><td class='line-number'><a name='L151' href='#L151'><pre>151</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L152' href='#L152'><pre>152</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        BlockWeights {</pre></td></tr><tr><td class='line-number'><a name='L153' href='#L153'><pre>153</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            attn_norm_weight: <span class='region red'>layer.attn_norm_weight</span>.<span class='region red'>clone</span>(),</pre></td></tr><tr><td class='line-number'><a name='L154' href='#L154'><pre>154</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            attn_norm_bias: <span class='region red'>layer.attn_norm_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>]),</pre></td></tr><tr><td class='line-number'><a name='L155' href='#L155'><pre>155</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            qkv_weight: <span class='region red'>qkv_weight_t</span>,</pre></td></tr><tr><td class='line-number'><a name='L156' href='#L156'><pre>156</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            qkv_bias: <span class='region red'>layer.qkv_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_default</span>(),</pre></td></tr><tr><td class='line-number'><a name='L157' href='#L157'><pre>157</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            out_weight: <span class='region red'>out_weight_t</span>,</pre></td></tr><tr><td class='line-number'><a name='L158' href='#L158'><pre>158</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            out_bias: <span class='region red'>layer.attn_output_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>]),</pre></td></tr><tr><td class='line-number'><a name='L159' href='#L159'><pre>159</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            // Use actual FFN norm if available, otherwise identity (Phase 21 fix)</pre></td></tr><tr><td class='line-number'><a name='L160' href='#L160'><pre>160</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            ffn_norm_weight: <span class='region red'>layer.ffn_norm_weight</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[1.0; <span class='region red'>hidden_dim</span>]),</pre></td></tr><tr><td class='line-number'><a name='L161' href='#L161'><pre>161</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            ffn_norm_bias: <span class='region red'>layer.ffn_norm_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>]),</pre></td></tr><tr><td class='line-number'><a name='L162' href='#L162'><pre>162</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            ffn_fc1_weight: <span class='region red'>fc1_weight_t</span>,</pre></td></tr><tr><td class='line-number'><a name='L163' href='#L163'><pre>163</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            ffn_fc1_bias: <span class='region red'>layer.ffn_up_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[0.0; <span class='region red'>intermediate_dim</span>]),</pre></td></tr><tr><td class='line-number'><a name='L164' href='#L164'><pre>164</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            ffn_fc2_weight: <span class='region red'>fc2_weight_t</span>,</pre></td></tr><tr><td class='line-number'><a name='L165' href='#L165'><pre>165</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            ffn_fc2_bias: <span class='region red'>layer.ffn_down_bias</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>]),</pre></td></tr><tr><td class='line-number'><a name='L166' href='#L166'><pre>166</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            // SwiGLU gate weight - critical for Qwen/LLaMA models</pre></td></tr><tr><td class='line-number'><a name='L167' href='#L167'><pre>167</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            ffn_gate_weight: <span class='region red'>gate_weight_t</span>,</pre></td></tr><tr><td class='line-number'><a name='L168' href='#L168'><pre>168</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        }</pre></td></tr><tr><td class='line-number'><a name='L169' href='#L169'><pre>169</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>}</span></pre></td></tr><tr><td class='line-number'><a name='L170' href='#L170'><pre>170</pre></a></td><td class='skipped-line'></td><td class='code'><pre>}</pre></td></tr><tr><td class='line-number'><a name='L171' href='#L171'><pre>171</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L172' href='#L172'><pre>172</pre></a></td><td class='skipped-line'></td><td class='code'><pre>/// Adapter for converting Q4 APR models to GPU format</pre></td></tr><tr><td class='line-number'><a name='L173' href='#L173'><pre>173</pre></a></td><td class='skipped-line'></td><td class='code'><pre>pub struct AprToGpuAdapter;</pre></td></tr><tr><td class='line-number'><a name='L174' href='#L174'><pre>174</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L175' href='#L175'><pre>175</pre></a></td><td class='skipped-line'></td><td class='code'><pre>impl AprToGpuAdapter {</pre></td></tr><tr><td class='line-number'><a name='L176' href='#L176'><pre>176</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Convert APR config to GPU config</pre></td></tr><tr><td class='line-number'><a name='L177' href='#L177'><pre>177</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    #[must_use]</pre></td></tr><tr><td class='line-number'><a name='L178' href='#L178'><pre>178</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    pub fn config_to_gpu(apr_config: &amp;AprTransformerConfig) -&gt; GpuModelConfig {</pre></td></tr><tr><td class='line-number'><a name='L179' href='#L179'><pre>179</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        GpuModelConfig {</pre></td></tr><tr><td class='line-number'><a name='L180' href='#L180'><pre>180</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            vocab_size: apr_config.vocab_size,</pre></td></tr><tr><td class='line-number'><a name='L181' href='#L181'><pre>181</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            hidden_dim: apr_config.hidden_dim,</pre></td></tr><tr><td class='line-number'><a name='L182' href='#L182'><pre>182</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            num_heads: apr_config.num_heads,</pre></td></tr><tr><td class='line-number'><a name='L183' href='#L183'><pre>183</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            num_kv_heads: apr_config.num_kv_heads,</pre></td></tr><tr><td class='line-number'><a name='L184' href='#L184'><pre>184</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            num_layers: apr_config.num_layers,</pre></td></tr><tr><td class='line-number'><a name='L185' href='#L185'><pre>185</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            intermediate_dim: apr_config.intermediate_dim,</pre></td></tr><tr><td class='line-number'><a name='L186' href='#L186'><pre>186</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            eps: apr_config.eps,</pre></td></tr><tr><td class='line-number'><a name='L187' href='#L187'><pre>187</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            rope_theta: apr_config.rope_theta,</pre></td></tr><tr><td class='line-number'><a name='L188' href='#L188'><pre>188</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        }</pre></td></tr><tr><td class='line-number'><a name='L189' href='#L189'><pre>189</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    }</pre></td></tr><tr><td class='line-number'><a name='L190' href='#L190'><pre>190</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L191' href='#L191'><pre>191</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Dequantize a Q4_0 tensor to F32</pre></td></tr><tr><td class='line-number'><a name='L192' href='#L192'><pre>192</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L193' href='#L193'><pre>193</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Arguments</pre></td></tr><tr><td class='line-number'><a name='L194' href='#L194'><pre>194</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L195' href='#L195'><pre>195</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// * `data` - Raw Q4_0 quantized bytes</pre></td></tr><tr><td class='line-number'><a name='L196' href='#L196'><pre>196</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// * `expected_elements` - Expected number of output elements</pre></td></tr><tr><td class='line-number'><a name='L197' href='#L197'><pre>197</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L198' href='#L198'><pre>198</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Returns</pre></td></tr><tr><td class='line-number'><a name='L199' href='#L199'><pre>199</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L200' href='#L200'><pre>200</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Dequantized F32 vector</pre></td></tr><tr><td class='line-number'><a name='L201' href='#L201'><pre>201</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>pub fn dequantize_tensor(data: &amp;[u8], expected_elements: usize) -&gt; Result&lt;Vec&lt;f32&gt;&gt;</span> {</pre></td></tr><tr><td class='line-number'><a name='L202' href='#L202'><pre>202</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>result</span> = <span class='region red'>dequantize_q4_0</span>(<span class='region red'>data</span>)<span class='region red'>?</span>;</pre></td></tr><tr><td class='line-number'><a name='L203' href='#L203'><pre>203</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L204' href='#L204'><pre>204</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Validate dimensions</pre></td></tr><tr><td class='line-number'><a name='L205' href='#L205'><pre>205</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        if <span class='region red'>result</span><span class='region red'>.len() &lt; expected_elements</span> {</pre></td></tr><tr><td class='line-number'><a name='L206' href='#L206'><pre>206</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            // Pad with zeros if needed (can happen with block alignment)</pre></td></tr><tr><td class='line-number'><a name='L207' href='#L207'><pre>207</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            let <span class='region red'>mut padded</span> = <span class='region red'>result</span>;</pre></td></tr><tr><td class='line-number'><a name='L208' href='#L208'><pre>208</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>padded</span>.<span class='region red'>resize</span>(<span class='region red'>expected_elements</span>, 0.0);</pre></td></tr><tr><td class='line-number'><a name='L209' href='#L209'><pre>209</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>Ok(padded)</span></pre></td></tr><tr><td class='line-number'><a name='L210' href='#L210'><pre>210</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        } else {</pre></td></tr><tr><td class='line-number'><a name='L211' href='#L211'><pre>211</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            // Truncate to expected size</pre></td></tr><tr><td class='line-number'><a name='L212' href='#L212'><pre>212</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>Ok(</span><span class='region red'>result</span><span class='region red'>.</span><span class='region red'>into_iter</span><span class='region red'>().</span><span class='region red'>take</span><span class='region red'>(expected_elements).collect())</span></pre></td></tr><tr><td class='line-number'><a name='L213' href='#L213'><pre>213</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        }</pre></td></tr><tr><td class='line-number'><a name='L214' href='#L214'><pre>214</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>}</span></pre></td></tr><tr><td class='line-number'><a name='L215' href='#L215'><pre>215</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L216' href='#L216'><pre>216</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Extract QKV weights from APR layer</pre></td></tr><tr><td class='line-number'><a name='L217' href='#L217'><pre>217</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L218' href='#L218'><pre>218</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// APR stores QKV as a single tensor, which matches GpuModel format.</pre></td></tr><tr><td class='line-number'><a name='L219' href='#L219'><pre>219</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>pub fn extract_qkv_weights(</span></pre></td></tr><tr><td class='line-number'><a name='L220' href='#L220'><pre>220</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        layer: &amp;QuantizedAprLayerQ4,</span></pre></td></tr><tr><td class='line-number'><a name='L221' href='#L221'><pre>221</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        hidden_dim: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L222' href='#L222'><pre>222</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        num_heads: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L223' href='#L223'><pre>223</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        num_kv_heads: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L224' href='#L224'><pre>224</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>    ) -&gt; Result&lt;Vec&lt;f32&gt;&gt;</span> {</pre></td></tr><tr><td class='line-number'><a name='L225' href='#L225'><pre>225</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>head_dim</span> = <span class='region red'>hidden_dim / num_heads</span>;</pre></td></tr><tr><td class='line-number'><a name='L226' href='#L226'><pre>226</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>kv_dim</span> = <span class='region red'>num_kv_heads * head_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L227' href='#L227'><pre>227</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>qkv_out_dim</span> = <span class='region red'>hidden_dim + 2 * kv_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L228' href='#L228'><pre>228</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>expected</span> = <span class='region red'>hidden_dim * qkv_out_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L229' href='#L229'><pre>229</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L230' href='#L230'><pre>230</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        <span class='region red'>Self::dequantize_tensor</span>(<span class='region red'>&amp;layer.qkv_weight.data</span>, <span class='region red'>expected</span>)</pre></td></tr><tr><td class='line-number'><a name='L231' href='#L231'><pre>231</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>}</span></pre></td></tr><tr><td class='line-number'><a name='L232' href='#L232'><pre>232</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L233' href='#L233'><pre>233</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Extract output projection weights</pre></td></tr><tr><td class='line-number'><a name='L234' href='#L234'><pre>234</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>pub fn extract_out_weights(</span></pre></td></tr><tr><td class='line-number'><a name='L235' href='#L235'><pre>235</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        layer: &amp;QuantizedAprLayerQ4,</span></pre></td></tr><tr><td class='line-number'><a name='L236' href='#L236'><pre>236</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        hidden_dim: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L237' href='#L237'><pre>237</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>    ) -&gt; Result&lt;Vec&lt;f32&gt;&gt;</span> {</pre></td></tr><tr><td class='line-number'><a name='L238' href='#L238'><pre>238</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>expected</span> = <span class='region red'>hidden_dim * hidden_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L239' href='#L239'><pre>239</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        <span class='region red'>Self::dequantize_tensor</span>(<span class='region red'>&amp;layer.attn_output_weight.data</span>, <span class='region red'>expected</span>)</pre></td></tr><tr><td class='line-number'><a name='L240' href='#L240'><pre>240</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>}</span></pre></td></tr><tr><td class='line-number'><a name='L241' href='#L241'><pre>241</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L242' href='#L242'><pre>242</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Extract FFN weights (fc1 = up, fc2 = down)</pre></td></tr><tr><td class='line-number'><a name='L243' href='#L243'><pre>243</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L244' href='#L244'><pre>244</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Note: APR uses SwiGLU with separate gate/up, but GpuModel combines them.</pre></td></tr><tr><td class='line-number'><a name='L245' href='#L245'><pre>245</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// For compatibility, we return up weights as fc1.</pre></td></tr><tr><td class='line-number'><a name='L246' href='#L246'><pre>246</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>pub fn extract_ffn_weights(</span></pre></td></tr><tr><td class='line-number'><a name='L247' href='#L247'><pre>247</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        layer: &amp;QuantizedAprLayerQ4,</span></pre></td></tr><tr><td class='line-number'><a name='L248' href='#L248'><pre>248</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        hidden_dim: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L249' href='#L249'><pre>249</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>        intermediate_dim: usize,</span></pre></td></tr><tr><td class='line-number'><a name='L250' href='#L250'><pre>250</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre><span class='region red'>    ) -&gt; Result&lt;(Vec&lt;f32&gt;, Vec&lt;f32&gt;)&gt;</span> {</pre></td></tr><tr><td class='line-number'><a name='L251' href='#L251'><pre>251</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // FC1 (up projection): [hidden_dim, intermediate_dim]</pre></td></tr><tr><td class='line-number'><a name='L252' href='#L252'><pre>252</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>fc1_expected</span> = <span class='region red'>hidden_dim * intermediate_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L253' href='#L253'><pre>253</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>fc1</span> = <span class='region red'>Self::dequantize_tensor</span>(<span class='region red'>&amp;layer.ffn_up_weight.data</span>, <span class='region red'>fc1_expected</span>)<span class='region red'>?</span>;</pre></td></tr><tr><td class='line-number'><a name='L254' href='#L254'><pre>254</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L255' href='#L255'><pre>255</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // FC2 (down projection): [intermediate_dim, hidden_dim]</pre></td></tr><tr><td class='line-number'><a name='L256' href='#L256'><pre>256</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>fc2_expected</span> = <span class='region red'>intermediate_dim * hidden_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L257' href='#L257'><pre>257</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>fc2</span> = <span class='region red'>Self::dequantize_tensor</span>(<span class='region red'>&amp;layer.ffn_down_weight.data</span>, <span class='region red'>fc2_expected</span>)<span class='region red'>?</span>;</pre></td></tr><tr><td class='line-number'><a name='L258' href='#L258'><pre>258</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L259' href='#L259'><pre>259</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        <span class='region red'>Ok((fc1, fc2))</span></pre></td></tr><tr><td class='line-number'><a name='L260' href='#L260'><pre>260</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>}</span></pre></td></tr><tr><td class='line-number'><a name='L261' href='#L261'><pre>261</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L262' href='#L262'><pre>262</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// Convert full APR transformer to GpuModel</pre></td></tr><tr><td class='line-number'><a name='L263' href='#L263'><pre>263</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L264' href='#L264'><pre>264</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Arguments</pre></td></tr><tr><td class='line-number'><a name='L265' href='#L265'><pre>265</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L266' href='#L266'><pre>266</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// * `apr` - Source APR transformer with Q4_0 weights</pre></td></tr><tr><td class='line-number'><a name='L267' href='#L267'><pre>267</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L268' href='#L268'><pre>268</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Returns</pre></td></tr><tr><td class='line-number'><a name='L269' href='#L269'><pre>269</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L270' href='#L270'><pre>270</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// `GpuModel` ready for GPU inference</pre></td></tr><tr><td class='line-number'><a name='L271' href='#L271'><pre>271</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L272' href='#L272'><pre>272</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// # Example</pre></td></tr><tr><td class='line-number'><a name='L273' href='#L273'><pre>273</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L274' href='#L274'><pre>274</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// ```ignore</pre></td></tr><tr><td class='line-number'><a name='L275' href='#L275'><pre>275</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// use realizar::apr_transformer::QuantizedAprTransformerQ4;</pre></td></tr><tr><td class='line-number'><a name='L276' href='#L276'><pre>276</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// use realizar::gpu::adapters::AprToGpuAdapter;</pre></td></tr><tr><td class='line-number'><a name='L277' href='#L277'><pre>277</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    ///</pre></td></tr><tr><td class='line-number'><a name='L278' href='#L278'><pre>278</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// let apr = QuantizedAprTransformerQ4::from_gguf(&amp;gguf_model);</pre></td></tr><tr><td class='line-number'><a name='L279' href='#L279'><pre>279</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// let gpu_model = AprToGpuAdapter::to_gpu_model(&amp;apr)?;</pre></td></tr><tr><td class='line-number'><a name='L280' href='#L280'><pre>280</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    /// ```</pre></td></tr><tr><td class='line-number'><a name='L281' href='#L281'><pre>281</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>pub fn to_gpu_model(apr: &amp;QuantizedAprTransformerQ4) -&gt; Result&lt;GpuModel&gt;</span> {</pre></td></tr><tr><td class='line-number'><a name='L282' href='#L282'><pre>282</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>config</span> = <span class='region red'>Self::config_to_gpu</span>(<span class='region red'>&amp;apr.config</span>);</pre></td></tr><tr><td class='line-number'><a name='L283' href='#L283'><pre>283</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>hidden_dim</span> = <span class='region red'>config.hidden_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L284' href='#L284'><pre>284</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>intermediate_dim</span> = <span class='region red'>config.intermediate_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L285' href='#L285'><pre>285</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L286' href='#L286'><pre>286</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Embedding weights (already F32 in APR)</pre></td></tr><tr><td class='line-number'><a name='L287' href='#L287'><pre>287</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>embedding_weights</span> = <span class='region red'>apr.token_embedding</span>.<span class='region red'>clone</span>();</pre></td></tr><tr><td class='line-number'><a name='L288' href='#L288'><pre>288</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L289' href='#L289'><pre>289</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Dequantize LM head</pre></td></tr><tr><td class='line-number'><a name='L290' href='#L290'><pre>290</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>lm_head_expected</span> = <span class='region red'>hidden_dim * config.vocab_size</span>;</pre></td></tr><tr><td class='line-number'><a name='L291' href='#L291'><pre>291</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>lm_head_weight</span> = <span class='region red'>Self::dequantize_tensor</span>(<span class='region red'>&amp;apr.lm_head_weight.data</span>, <span class='region red'>lm_head_expected</span>)<span class='region red'>?</span>;</pre></td></tr><tr><td class='line-number'><a name='L292' href='#L292'><pre>292</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L293' href='#L293'><pre>293</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Phase 22 FIX: Transpose LM head from APR [vocab_size, hidden_dim] to GPU [hidden_dim, vocab_size]</pre></td></tr><tr><td class='line-number'><a name='L294' href='#L294'><pre>294</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // APR stores weights as [out_dim, in_dim], GPU matmul expects [in_dim, out_dim]</pre></td></tr><tr><td class='line-number'><a name='L295' href='#L295'><pre>295</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>lm_head_weight_t</span> = <span class='region red'>transpose_matrix</span>(<span class='region red'>&amp;lm_head_weight</span>, <span class='region red'>config.vocab_size</span>, <span class='region red'>hidden_dim</span>);</pre></td></tr><tr><td class='line-number'><a name='L296' href='#L296'><pre>296</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L297' href='#L297'><pre>297</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Convert each layer</pre></td></tr><tr><td class='line-number'><a name='L298' href='#L298'><pre>298</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>mut block_weights</span> = <span class='region red'>Vec::with_capacity</span>(<span class='region red'>apr.layers</span>.<span class='region red'>len</span>());</pre></td></tr><tr><td class='line-number'><a name='L299' href='#L299'><pre>299</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        for <span class='region red'>layer</span> in <span class='region red'>&amp;apr.layers</span> {</pre></td></tr><tr><td class='line-number'><a name='L300' href='#L300'><pre>300</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            let <span class='region red'>qkv</span> = <span class='region red'>Self::extract_qkv_weights</span>(<span class='region red'>layer</span>, <span class='region red'>hidden_dim</span>, <span class='region red'>config.num_heads</span>, <span class='region red'>config.num_kv_heads</span>)<span class='region red'>?</span>;</pre></td></tr><tr><td class='line-number'><a name='L301' href='#L301'><pre>301</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            let <span class='region red'>out</span> = <span class='region red'>Self::extract_out_weights</span>(<span class='region red'>layer</span>, <span class='region red'>hidden_dim</span>)<span class='region red'>?</span>;</pre></td></tr><tr><td class='line-number'><a name='L302' href='#L302'><pre>302</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            let (<span class='region red'>fc1</span>, <span class='region red'>fc2</span>) = <span class='region red'>Self::extract_ffn_weights</span>(<span class='region red'>layer</span>, <span class='region red'>hidden_dim</span>, <span class='region red'>intermediate_dim</span>)<span class='region red'>?</span>;</pre></td></tr><tr><td class='line-number'><a name='L303' href='#L303'><pre>303</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L304' href='#L304'><pre>304</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            // Extract gate weight for SwiGLU (optional)</pre></td></tr><tr><td class='line-number'><a name='L305' href='#L305'><pre>305</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            let <span class='region red'>ffn_gate_weight</span> = if let Some(<span class='region red'>ref gate</span>) = <span class='region red'>layer.ffn_gate_weight</span> {</pre></td></tr><tr><td class='line-number'><a name='L306' href='#L306'><pre>306</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                let <span class='region red'>gate_expected</span> = <span class='region red'>hidden_dim * intermediate_dim</span>;</pre></td></tr><tr><td class='line-number'><a name='L307' href='#L307'><pre>307</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                Some(<span class='region red'>Self::dequantize_tensor</span>(<span class='region red'>&amp;gate.data</span>, <span class='region red'>gate_expected</span>)<span class='region red'>?</span>)</pre></td></tr><tr><td class='line-number'><a name='L308' href='#L308'><pre>308</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            } else {</pre></td></tr><tr><td class='line-number'><a name='L309' href='#L309'><pre>309</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                <span class='region red'>None</span></pre></td></tr><tr><td class='line-number'><a name='L310' href='#L310'><pre>310</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            };</pre></td></tr><tr><td class='line-number'><a name='L311' href='#L311'><pre>311</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L312' href='#L312'><pre>312</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>block_weights</span>.<span class='region red'>push</span>(BlockWeights {</pre></td></tr><tr><td class='line-number'><a name='L313' href='#L313'><pre>313</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                attn_norm_weight: <span class='region red'>layer.attn_norm_weight</span>.<span class='region red'>clone</span>(),</pre></td></tr><tr><td class='line-number'><a name='L314' href='#L314'><pre>314</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                attn_norm_bias: <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>], // APR doesn&apos;t use bias</pre></td></tr><tr><td class='line-number'><a name='L315' href='#L315'><pre>315</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                qkv_weight: <span class='region red'>qkv</span>,</pre></td></tr><tr><td class='line-number'><a name='L316' href='#L316'><pre>316</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                qkv_bias: <span class='region red'>vec!</span>[], // No bias in APR</pre></td></tr><tr><td class='line-number'><a name='L317' href='#L317'><pre>317</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                out_weight: <span class='region red'>out</span>,</pre></td></tr><tr><td class='line-number'><a name='L318' href='#L318'><pre>318</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                out_bias: <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>],</pre></td></tr><tr><td class='line-number'><a name='L319' href='#L319'><pre>319</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                ffn_norm_weight: <span class='region red'>layer.ffn_norm_weight</span>.<span class='region red'>clone</span>().<span class='region red'>unwrap_or_else</span>(|| <span class='region red'>vec!</span>[1.0; <span class='region red'>hidden_dim</span>]),</pre></td></tr><tr><td class='line-number'><a name='L320' href='#L320'><pre>320</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                ffn_norm_bias: <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>],</pre></td></tr><tr><td class='line-number'><a name='L321' href='#L321'><pre>321</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                ffn_fc1_weight: <span class='region red'>fc1</span>,</pre></td></tr><tr><td class='line-number'><a name='L322' href='#L322'><pre>322</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                ffn_fc1_bias: <span class='region red'>vec!</span>[0.0; <span class='region red'>intermediate_dim</span>],</pre></td></tr><tr><td class='line-number'><a name='L323' href='#L323'><pre>323</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                ffn_fc2_weight: <span class='region red'>fc2</span>,</pre></td></tr><tr><td class='line-number'><a name='L324' href='#L324'><pre>324</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                ffn_fc2_bias: <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>],</pre></td></tr><tr><td class='line-number'><a name='L325' href='#L325'><pre>325</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>                <span class='region red'>ffn_gate_weight</span>,</pre></td></tr><tr><td class='line-number'><a name='L326' href='#L326'><pre>326</pre></a></td><td class='skipped-line'></td><td class='code'><pre>            });</pre></td></tr><tr><td class='line-number'><a name='L327' href='#L327'><pre>327</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        }</pre></td></tr><tr><td class='line-number'><a name='L328' href='#L328'><pre>328</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L329' href='#L329'><pre>329</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Final norm</pre></td></tr><tr><td class='line-number'><a name='L330' href='#L330'><pre>330</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>final_norm_weight</span> = <span class='region red'>apr.output_norm_weight</span>.<span class='region red'>clone</span>();</pre></td></tr><tr><td class='line-number'><a name='L331' href='#L331'><pre>331</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>final_norm_bias</span> = <span class='region red'>vec!</span>[0.0; <span class='region red'>hidden_dim</span>];</pre></td></tr><tr><td class='line-number'><a name='L332' href='#L332'><pre>332</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L333' href='#L333'><pre>333</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // LM head bias</pre></td></tr><tr><td class='line-number'><a name='L334' href='#L334'><pre>334</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        let <span class='region red'>lm_head_bias</span> = <span class='region red'>vec!</span>[0.0; <span class='region red'>config.vocab_size</span>];</pre></td></tr><tr><td class='line-number'><a name='L335' href='#L335'><pre>335</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L336' href='#L336'><pre>336</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        // Create GpuModel using internal constructor</pre></td></tr><tr><td class='line-number'><a name='L337' href='#L337'><pre>337</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>        <span class='region red'>GpuModel::from_apr_weights</span>(</pre></td></tr><tr><td class='line-number'><a name='L338' href='#L338'><pre>338</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>config</span>,</pre></td></tr><tr><td class='line-number'><a name='L339' href='#L339'><pre>339</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>embedding_weights</span>,</pre></td></tr><tr><td class='line-number'><a name='L340' href='#L340'><pre>340</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>block_weights</span>,</pre></td></tr><tr><td class='line-number'><a name='L341' href='#L341'><pre>341</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>final_norm_weight</span>,</pre></td></tr><tr><td class='line-number'><a name='L342' href='#L342'><pre>342</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>final_norm_bias</span>,</pre></td></tr><tr><td class='line-number'><a name='L343' href='#L343'><pre>343</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>lm_head_weight</span>,</pre></td></tr><tr><td class='line-number'><a name='L344' href='#L344'><pre>344</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>lm_head_weight_t</span>,</pre></td></tr><tr><td class='line-number'><a name='L345' href='#L345'><pre>345</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>            <span class='region red'>lm_head_bias</span>,</pre></td></tr><tr><td class='line-number'><a name='L346' href='#L346'><pre>346</pre></a></td><td class='skipped-line'></td><td class='code'><pre>        )</pre></td></tr><tr><td class='line-number'><a name='L347' href='#L347'><pre>347</pre></a></td><td class='uncovered-line'><pre>0</pre></td><td class='code'><pre>    <span class='region red'>}</span></pre></td></tr><tr><td class='line-number'><a name='L348' href='#L348'><pre>348</pre></a></td><td class='skipped-line'></td><td class='code'><pre>}</pre></td></tr><tr><td class='line-number'><a name='L349' href='#L349'><pre>349</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L350' href='#L350'><pre>350</pre></a></td><td class='skipped-line'></td><td class='code'><pre>/// Transpose a row-major matrix</pre></td></tr><tr><td class='line-number'><a name='L351' href='#L351'><pre>351</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>fn transpose_matrix(data: &amp;[f32], rows: usize, cols: usize) -&gt; Vec&lt;f32&gt; {</pre></td></tr><tr><td class='line-number'><a name='L352' href='#L352'><pre>352</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    let mut transposed = vec![0.0; rows * cols];</pre></td></tr><tr><td class='line-number'><a name='L353' href='#L353'><pre>353</pre></a></td><td class='covered-line'><pre>4</pre></td><td class='code'><pre>    for i in 0..<div class='tooltip'>rows<span class='tooltip-content'>2</span></div> {</pre></td></tr><tr><td class='line-number'><a name='L354' href='#L354'><pre>354</pre></a></td><td class='covered-line'><pre>10</pre></td><td class='code'><pre>        for j in 0..<div class='tooltip'>cols<span class='tooltip-content'>4</span></div> {</pre></td></tr><tr><td class='line-number'><a name='L355' href='#L355'><pre>355</pre></a></td><td class='covered-line'><pre>10</pre></td><td class='code'><pre>            transposed[j * rows + i] = data[i * cols + j];</pre></td></tr><tr><td class='line-number'><a name='L356' href='#L356'><pre>356</pre></a></td><td class='covered-line'><pre>10</pre></td><td class='code'><pre>        }</pre></td></tr><tr><td class='line-number'><a name='L357' href='#L357'><pre>357</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    }</pre></td></tr><tr><td class='line-number'><a name='L358' href='#L358'><pre>358</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>    transposed</pre></td></tr><tr><td class='line-number'><a name='L359' href='#L359'><pre>359</pre></a></td><td class='covered-line'><pre>2</pre></td><td class='code'><pre>}</pre></td></tr><tr><td class='line-number'><a name='L360' href='#L360'><pre>360</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L361' href='#L361'><pre>361</pre></a></td><td class='skipped-line'></td><td class='code'><pre>#[cfg(test)]</pre></td></tr><tr><td class='line-number'><a name='L362' href='#L362'><pre>362</pre></a></td><td class='skipped-line'></td><td class='code'><pre>mod tests {</pre></td></tr><tr><td class='line-number'><a name='L363' href='#L363'><pre>363</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    use super::*;</pre></td></tr><tr><td class='line-number'><a name='L364' href='#L364'><pre>364</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    use crate::apr_transformer::AprTransformerConfig;</pre></td></tr><tr><td class='line-number'><a name='L365' href='#L365'><pre>365</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L366' href='#L366'><pre>366</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    #[test]</pre></td></tr><tr><td class='line-number'><a name='L367' href='#L367'><pre>367</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    fn test_config_to_gpu() {</pre></td></tr><tr><td class='line-number'><a name='L368' href='#L368'><pre>368</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        let apr_config = AprTransformerConfig {</pre></td></tr><tr><td class='line-number'><a name='L369' href='#L369'><pre>369</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            architecture: &quot;test&quot;.to_string(),</pre></td></tr><tr><td class='line-number'><a name='L370' href='#L370'><pre>370</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            hidden_dim: 512,</pre></td></tr><tr><td class='line-number'><a name='L371' href='#L371'><pre>371</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            num_layers: 4,</pre></td></tr><tr><td class='line-number'><a name='L372' href='#L372'><pre>372</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            num_heads: 8,</pre></td></tr><tr><td class='line-number'><a name='L373' href='#L373'><pre>373</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            num_kv_heads: 4,</pre></td></tr><tr><td class='line-number'><a name='L374' href='#L374'><pre>374</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            vocab_size: 32000,</pre></td></tr><tr><td class='line-number'><a name='L375' href='#L375'><pre>375</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            intermediate_dim: 1024,</pre></td></tr><tr><td class='line-number'><a name='L376' href='#L376'><pre>376</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            context_length: 2048,</pre></td></tr><tr><td class='line-number'><a name='L377' href='#L377'><pre>377</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            rope_theta: 10000.0,</pre></td></tr><tr><td class='line-number'><a name='L378' href='#L378'><pre>378</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>            eps: 1e-5,</pre></td></tr><tr><td class='line-number'><a name='L379' href='#L379'><pre>379</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        };</pre></td></tr><tr><td class='line-number'><a name='L380' href='#L380'><pre>380</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L381' href='#L381'><pre>381</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        let gpu_config = AprToGpuAdapter::config_to_gpu(&amp;apr_config);</pre></td></tr><tr><td class='line-number'><a name='L382' href='#L382'><pre>382</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L383' href='#L383'><pre>383</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(gpu_config.vocab_size, 32000);</pre></td></tr><tr><td class='line-number'><a name='L384' href='#L384'><pre>384</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(gpu_config.hidden_dim, 512);</pre></td></tr><tr><td class='line-number'><a name='L385' href='#L385'><pre>385</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(gpu_config.num_heads, 8);</pre></td></tr><tr><td class='line-number'><a name='L386' href='#L386'><pre>386</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(gpu_config.num_kv_heads, 4);</pre></td></tr><tr><td class='line-number'><a name='L387' href='#L387'><pre>387</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(gpu_config.num_layers, 4);</pre></td></tr><tr><td class='line-number'><a name='L388' href='#L388'><pre>388</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(gpu_config.intermediate_dim, 1024);</pre></td></tr><tr><td class='line-number'><a name='L389' href='#L389'><pre>389</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(gpu_config.eps, 1e-5);</pre></td></tr><tr><td class='line-number'><a name='L390' href='#L390'><pre>390</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    }</pre></td></tr><tr><td class='line-number'><a name='L391' href='#L391'><pre>391</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L392' href='#L392'><pre>392</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    #[test]</pre></td></tr><tr><td class='line-number'><a name='L393' href='#L393'><pre>393</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    fn test_transpose_matrix() {</pre></td></tr><tr><td class='line-number'><a name='L394' href='#L394'><pre>394</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        let data = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0]; // 2x3</pre></td></tr><tr><td class='line-number'><a name='L395' href='#L395'><pre>395</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        let transposed = transpose_matrix(&amp;data, 2, 3); // 3x2</pre></td></tr><tr><td class='line-number'><a name='L396' href='#L396'><pre>396</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L397' href='#L397'><pre>397</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(transposed, vec![1.0, 4.0, 2.0, 5.0, 3.0, 6.0]);</pre></td></tr><tr><td class='line-number'><a name='L398' href='#L398'><pre>398</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    }</pre></td></tr><tr><td class='line-number'><a name='L399' href='#L399'><pre>399</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L400' href='#L400'><pre>400</pre></a></td><td class='skipped-line'></td><td class='code'><pre>    #[test]</pre></td></tr><tr><td class='line-number'><a name='L401' href='#L401'><pre>401</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    fn test_transpose_identity() {</pre></td></tr><tr><td class='line-number'><a name='L402' href='#L402'><pre>402</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        let data = vec![1.0, 2.0, 3.0, 4.0]; // 2x2</pre></td></tr><tr><td class='line-number'><a name='L403' href='#L403'><pre>403</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        let transposed = transpose_matrix(&amp;data, 2, 2);</pre></td></tr><tr><td class='line-number'><a name='L404' href='#L404'><pre>404</pre></a></td><td class='skipped-line'></td><td class='code'><pre></pre></td></tr><tr><td class='line-number'><a name='L405' href='#L405'><pre>405</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>        assert_eq!(transposed, vec![1.0, 3.0, 2.0, 4.0]);</pre></td></tr><tr><td class='line-number'><a name='L406' href='#L406'><pre>406</pre></a></td><td class='covered-line'><pre>1</pre></td><td class='code'><pre>    }</pre></td></tr><tr><td class='line-number'><a name='L407' href='#L407'><pre>407</pre></a></td><td class='skipped-line'></td><td class='code'><pre>}</pre></td></tr></table></div></body></html>