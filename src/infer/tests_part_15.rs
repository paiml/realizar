
    #[test]
    fn test_clean_model_output_im_start_im_end_ext_cov() {
        // Function removes markers but keeps content between them
        let raw = "<|im_start|>assistant\nHi there!<|im_end|>";
        let cleaned = clean_model_output(raw);
        assert_eq!(cleaned, "Hi there!");
    }

    #[test]
    fn test_clean_model_output_empty_ext_cov() {
        let raw = "";
        let cleaned = clean_model_output(raw);
        assert_eq!(cleaned, "");
    }

    #[test]
    fn test_clean_model_output_only_markers_ext_cov() {
        let raw = "<|im_start|><|im_end|><|endoftext|>";
        let cleaned = clean_model_output(raw);
        assert_eq!(cleaned, "");
    }

    #[test]
    fn test_clean_model_output_multiple_endoftext_ext_cov() {
        let raw = "Text<|endoftext|>More text<|endoftext|>";
        let cleaned = clean_model_output(raw);
        assert_eq!(cleaned, "TextMore text");
    }

    // =========================================================================
    // Extended Coverage Tests: prefault_mmap
    // =========================================================================

    #[test]
    fn test_prefault_mmap_large_ext_cov() {
        let data = vec![0u8; 4096 * 10]; // 10 pages
        prefault_mmap(&data);
    }

    #[test]
    fn test_prefault_mmap_not_page_aligned_ext_cov() {
        let data = vec![0u8; 5000]; // Not page-aligned
        prefault_mmap(&data);
    }

    // =========================================================================
    // Extended Coverage Tests: InferenceResult
    // =========================================================================

    #[test]
    fn test_inference_result_debug_ext_cov() {
        let result = InferenceResult {
            text: "test".to_string(),
            tokens: vec![1],
            input_token_count: 1,
            generated_token_count: 0,
            inference_ms: 5.0,
            tok_per_sec: 0.0,
            load_ms: 2.0,
            format: "APR".to_string(),
            used_gpu: false,
        };
        let debug_str = format!("{:?}", result);
        assert!(debug_str.contains("text"));
        assert!(debug_str.contains("tokens"));
        assert!(debug_str.contains("format"));
        assert!(debug_str.contains("used_gpu"));
    }

    #[test]
    fn test_inference_result_zero_values_ext_cov() {
        let result = InferenceResult {
            text: String::new(),
            tokens: vec![],
            input_token_count: 0,
            generated_token_count: 0,
            inference_ms: 0.0,
            tok_per_sec: 0.0,
            load_ms: 0.0,
            format: String::new(),
            used_gpu: false,
        };
        assert!(result.text.is_empty());
        assert!(result.tokens.is_empty());
        assert_eq!(result.input_token_count, 0);
    }

    #[test]
    fn test_inference_result_large_values_ext_cov() {
        let result = InferenceResult {
            text: "A".repeat(10000),
            tokens: vec![1; 1000],
            input_token_count: 100,
            generated_token_count: 900,
            inference_ms: 1000000.0,
            tok_per_sec: 1000.0,
            load_ms: 5000.0,
            format: "GGUF".to_string(),
            used_gpu: true,
        };
        assert_eq!(result.text.len(), 10000);
        assert_eq!(result.tokens.len(), 1000);
        assert_eq!(result.generated_token_count, 900);
    }

    #[test]
    fn test_inference_result_formats_ext_cov() {
        for fmt in ["GGUF", "APR", "SafeTensors"] {
            let result = InferenceResult {
                text: "test".to_string(),
                tokens: vec![1],
                input_token_count: 1,
                generated_token_count: 0,
                inference_ms: 1.0,
                tok_per_sec: 1.0,
                load_ms: 1.0,
                format: fmt.to_string(),
                used_gpu: false,
            };
            assert_eq!(result.format, fmt);
        }
    }

    // =========================================================================
    // Extended Coverage Tests: run_inference error paths
    // =========================================================================

    #[test]
    fn test_run_inference_permission_denied_ext_cov() {
        // Try to read from a path that likely doesn't exist or isn't readable
        let config = InferenceConfig::new("/root/super_secret/model.gguf");
        let result = run_inference(&config);
        assert!(result.is_err());
    }

    #[test]
    fn test_run_inference_empty_path_ext_cov() {
        let config = InferenceConfig::new("");
        let result = run_inference(&config);
        assert!(result.is_err());
    }

    // =========================================================================
    // Deep Coverage Tests (_deep_icov_) - Lines 197-280
    // =========================================================================

    // --- Format Detection Tests (Lines 197-201) ---

    #[test]
    fn test_format_detection_gguf_magic_deep_icov() {
        // GGUF magic bytes: 0x47 0x47 0x55 0x46 = "GGUF"
        use crate::format::{detect_format, ModelFormat};
        let data = vec![0x47, 0x47, 0x55, 0x46, 0x03, 0x00, 0x00, 0x00];
        let format = detect_format(&data);
        assert!(matches!(format, Ok(ModelFormat::Gguf)));
    }

    #[test]
    fn test_format_detection_apr_magic_deep_icov() {
        // APR magic bytes: "APR\0"
        use crate::format::{detect_format, ModelFormat};
        let data = b"APR\0xxxx";
        let format = detect_format(data);
        assert!(matches!(format, Ok(ModelFormat::Apr)));
    }

    #[test]
    fn test_format_detection_safetensors_deep_icov() {
        // SafeTensors: first 8 bytes are header size (little-endian u64)
        use crate::format::{detect_format, ModelFormat};
        let header_size: u64 = 2048;
        let data = header_size.to_le_bytes();
        let format = detect_format(&data);
        assert!(matches!(format, Ok(ModelFormat::SafeTensors)));
    }

    #[test]
    fn test_format_detection_unknown_magic_deep_icov() {
        // Unknown magic bytes should return error
        use crate::format::{detect_format, FormatError};
        let data = b"\x00\x00\x00\x00\x00\x00\x00\x00"; // Zero header = unknown
        let format = detect_format(data);
        assert!(matches!(format, Err(FormatError::UnknownFormat)));
    }

    // --- Architecture Detection Tests (Lines 227-243) ---

    fn detect_arch_from_stem(stem: &str) -> &'static str {
        let lower = stem.to_lowercase();
        [("qwen", "Qwen2"), ("llama", "LLaMA"), ("mistral", "Mistral"), ("phi", "Phi")]
            .iter()
            .find(|(k, _)| lower.contains(k))
            .map_or("Transformer", |(_, v)| v)
    }

    #[test]
    fn test_architecture_detection_qwen_deep_icov() {
        let path = PathBuf::from("/models/qwen2-7b-instruct-q4.gguf");
        let arch = path.file_stem().and_then(|s| s.to_str()).map(detect_arch_from_stem);
        assert_eq!(arch, Some("Qwen2"));
    }

    #[test]
    fn test_architecture_detection_llama_deep_icov() {
        let path = PathBuf::from("/models/llama-3.1-8b-instruct.gguf");
        let arch = path.file_stem().and_then(|s| s.to_str()).map(detect_arch_from_stem);
        assert_eq!(arch, Some("LLaMA"));
    }

    #[test]
    fn test_architecture_detection_mistral_deep_icov() {
        let path = PathBuf::from("/models/mistral-7b-v0.2-q4_k_m.gguf");
        let arch = path.file_stem().and_then(|s| s.to_str()).map(detect_arch_from_stem);
        assert_eq!(arch, Some("Mistral"));
    }

    #[test]
    fn test_architecture_detection_phi_deep_icov() {
        let path = PathBuf::from("/models/phi-2-q4_0.gguf");
        let arch = path.file_stem().and_then(|s| s.to_str()).map(detect_arch_from_stem);
        assert_eq!(arch, Some("Phi"));
    }

    #[test]
    fn test_architecture_detection_transformer_fallback_deep_icov() {
        let path = PathBuf::from("/models/custom-model-q8_0.gguf");
        let arch = path.file_stem().and_then(|s| s.to_str()).map(detect_arch_from_stem);
        assert_eq!(arch, Some("Transformer"));
    }

    #[test]
    fn test_architecture_detection_case_insensitive_deep_icov() {
        let cases = [
            ("/models/QWEN2-7B.gguf", "Qwen2"),
            ("/models/LLAMA-3.gguf", "LLaMA"),
            ("/models/MISTRAL-7B.gguf", "Mistral"),
            ("/models/PHI-2.gguf", "Phi"),
            ("/models/QwEn2-MixedCase.gguf", "Qwen2"),
        ];
        for (path_str, expected) in cases {
            let path = PathBuf::from(path_str);
            let arch = path.file_stem().and_then(|s| s.to_str()).map(detect_arch_from_stem);
            assert_eq!(arch, Some(expected), "Failed for path: {path_str}");
        }
    }

    #[test]
    fn test_architecture_detection_no_extension_deep_icov() {
        let path = PathBuf::from("/models/qwen2-model");
        let arch = path.file_stem().and_then(|s| s.to_str()).map(detect_arch_from_stem);
        assert_eq!(arch, Some("Qwen2"));
    }

    // --- Instruct Model Detection Tests (Lines 264-270) ---

    #[test]
    fn test_instruct_model_detection_deep_icov() {
        let model_name = "llama-3.1-8b-instruct.gguf";
        let is_instruct = model_name.to_lowercase().contains("instruct");
        assert!(is_instruct);
    }

    #[test]
    fn test_instruct_model_detection_uppercase_deep_icov() {
        let model_name = "LLAMA-3.1-8B-INSTRUCT.gguf";
        let is_instruct = model_name.to_lowercase().contains("instruct");
        assert!(is_instruct);
    }

    #[test]
    fn test_instruct_model_detection_mixed_case_deep_icov() {
        let model_name = "Qwen2-7B-Instruct-Q4_K_M.gguf";
        let is_instruct = model_name.to_lowercase().contains("instruct");
        assert!(is_instruct);
    }

    #[test]
    fn test_instruct_model_detection_not_instruct_deep_icov() {
        let model_name = "llama-3.1-8b-base.gguf";
        let is_instruct = model_name.to_lowercase().contains("instruct");
        assert!(!is_instruct);
    }

    #[test]
    fn test_instruct_model_detection_partial_match_deep_icov() {
        // Should match even if "instruct" is part of a larger word
        let model_name = "model-instructed.gguf";
        let is_instruct = model_name.to_lowercase().contains("instruct");
        assert!(is_instruct);
    }

    // --- Chat Template Formatting Tests (Lines 266-270) ---

    #[test]
    fn test_chat_message_user_creation_deep_icov() {
        use crate::chat_template::ChatMessage;
        let msg = ChatMessage::user("Hello, world!");
        assert_eq!(msg.role, "user");
        assert_eq!(msg.content, "Hello, world!");
    }

    #[test]
    fn test_chat_message_system_creation_deep_icov() {
        use crate::chat_template::ChatMessage;
        let msg = ChatMessage::system("You are a helpful assistant.");
        assert_eq!(msg.role, "system");
        assert_eq!(msg.content, "You are a helpful assistant.");
    }

    #[test]
    fn test_format_messages_instruct_model_deep_icov() {
        use crate::chat_template::{format_messages, ChatMessage};
        let messages = vec![ChatMessage::user("What is 2+2?")];
        // Test with qwen model name (should use ChatML template)
        let result = format_messages(&messages, Some("qwen2-7b-instruct.gguf"));
        assert!(result.is_ok());
        let formatted = result.expect("operation failed");
        // ChatML format uses <|im_start|> markers
        assert!(formatted.contains("<|im_start|>") || formatted.contains("user"));
    }

    #[test]
    fn test_format_messages_llama_template_deep_icov() {
        use crate::chat_template::{format_messages, ChatMessage};
        let messages = vec![ChatMessage::user("Hello!")];
        let result = format_messages(&messages, Some("llama-3.1-8b-instruct.gguf"));
        assert!(result.is_ok());
        let formatted = result.expect("operation failed");
        // LLaMA format uses [INST] markers
        assert!(formatted.contains("[INST]") || formatted.contains("user"));
    }

    #[test]
    fn test_format_messages_fallback_raw_deep_icov() {
        use crate::chat_template::{format_messages, ChatMessage};
        let messages = vec![ChatMessage::user("Just text")];
        // Unknown model should use raw template
        let result = format_messages(&messages, Some("unknown-model.gguf"));
        assert!(result.is_ok());
    }

    // --- Input Token Handling Tests (Lines 255-279) ---

    #[test]
    fn test_input_tokens_priority_over_prompt_deep_icov() {
        // Test that input_tokens takes priority over prompt
        let config = InferenceConfig::new("/model.gguf")
            .with_prompt("Hello")
            .with_input_tokens(vec![1, 2, 3, 4]);

        // When both are set, input_tokens should be used (line 255-256)
        assert!(config.input_tokens.is_some());
        assert!(config.prompt.is_some());

        // Simulate the logic from run_gguf_inference
        let input_tokens = if let Some(ref tokens) = config.input_tokens {
            tokens.clone()
        } else if let Some(ref _prompt) = config.prompt {
            vec![100, 200] // Would be tokenized prompt
        } else {
            vec![1u32] // BOS token
        };
        assert_eq!(input_tokens, vec![1, 2, 3, 4]);
    }

    #[test]
    fn test_input_tokens_none_uses_prompt_deep_icov() {
        let config = InferenceConfig::new("/model.gguf").with_prompt("Hello");

        // When input_tokens is None, prompt should be used (line 257)
        assert!(config.input_tokens.is_none());
        assert!(config.prompt.is_some());
    }

    #[test]
    fn test_input_tokens_none_prompt_none_uses_bos_deep_icov() {
        let config = InferenceConfig::new("/model.gguf");

        // When both are None, BOS token should be used (line 277-278)
        assert!(config.input_tokens.is_none());
        assert!(config.prompt.is_none());

        // Simulate the logic
        let input_tokens = if let Some(ref tokens) = config.input_tokens {
            tokens.clone()
        } else if let Some(ref _prompt) = config.prompt {
            vec![100, 200]
        } else {
            vec![1u32] // BOS token
        };
        assert_eq!(input_tokens, vec![1u32]);
    }

    // --- Verbose Output Tests (Lines 210-252) ---

    #[test]
    fn test_verbose_flag_enabled_deep_icov() {
        let config = InferenceConfig::new("/model.gguf").with_verbose(true);
        assert!(config.verbose);
    }

    #[test]
    fn test_verbose_flag_disabled_deep_icov() {
        let config = InferenceConfig::new("/model.gguf").with_verbose(false);
        assert!(!config.verbose);
    }

    #[test]
    fn test_verbose_default_is_false_deep_icov() {
        let config = InferenceConfig::new("/model.gguf");
        assert!(!config.verbose);
    }

    // --- Model Name Extraction Tests ---

    #[test]
    fn test_model_name_extraction_from_path_deep_icov() {
        let path = PathBuf::from("/models/qwen2-7b-instruct.gguf");
        let model_name = path.file_name().and_then(|n| n.to_str()).unwrap_or("");
        assert_eq!(model_name, "qwen2-7b-instruct.gguf");
    }

    #[test]
    fn test_model_name_extraction_no_parent_deep_icov() {
        let path = PathBuf::from("qwen2-7b.gguf");
        let model_name = path.file_name().and_then(|n| n.to_str()).unwrap_or("");
        assert_eq!(model_name, "qwen2-7b.gguf");
    }

    #[test]
    fn test_model_name_extraction_empty_path_deep_icov() {
        let path = PathBuf::from("");
        let model_name = path.file_name().and_then(|n| n.to_str()).unwrap_or("");
        assert_eq!(model_name, "");
    }

    // --- File Stem Extraction Tests ---

    #[test]
    fn test_file_stem_extraction_deep_icov() {
        let path = PathBuf::from("/models/llama-3.1-8b.gguf");
        let stem = path.file_stem().and_then(|s| s.to_str());
        assert_eq!(stem, Some("llama-3.1-8b"));
    }
