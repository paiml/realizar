
#[tokio::test]
async fn test_openai_chat_completions_model_default() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "default",
        "messages": [{"role": "user", "content": "Test"}]
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert!(
        response.status() == StatusCode::OK
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
}

#[tokio::test]
async fn test_openai_chat_completions_empty_model() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "",
        "messages": [{"role": "user", "content": "Test"}]
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    // Empty model should use default
    assert!(
        response.status() == StatusCode::OK
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
}

#[tokio::test]
async fn test_openai_chat_completions_invalid_model() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "nonexistent-model-xyz",
        "messages": [{"role": "user", "content": "Test"}]
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    // Demo mode uses a default model, so this returns OK even with invalid model name
    // The handler falls back to the default model when registry lookup fails
    assert!(
        response.status() == StatusCode::OK
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
}

#[tokio::test]
async fn test_openai_chat_completions_multi_turn_conversation() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "default",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "What is 2+2?"},
            {"role": "assistant", "content": "2+2 equals 4."},
            {"role": "user", "content": "Thanks!"}
        ],
        "max_tokens": 5
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert!(
        response.status() == StatusCode::OK
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
}

#[tokio::test]
async fn test_openai_chat_completions_invalid_json() {
    let app = create_test_app_shared();

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .body(Body::from("not valid json"))
                .unwrap(),
        )
        .await
        .unwrap();

    // Invalid JSON returns 400 Bad Request (axum's Json extractor behavior)
    assert!(
        response.status() == StatusCode::BAD_REQUEST
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
}

#[tokio::test]
async fn test_openai_chat_completions_missing_messages() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "default"
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    // Missing required field should return 422
    assert_eq!(response.status(), StatusCode::UNPROCESSABLE_ENTITY);
}

#[tokio::test]
async fn test_openai_chat_completions_with_trace_header_brick() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "default",
        "messages": [{"role": "user", "content": "Hi"}]
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .header("X-Trace-Level", "brick")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert!(
        response.status() == StatusCode::OK
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
    if response.status() != StatusCode::OK {
        return;
    }

    let body = axum::body::to_bytes(response.into_body(), usize::MAX)
        .await
        .unwrap();
    let _result: ChatCompletionResponse = match serde_json::from_slice(&body) {
        Ok(v) => v,
        Err(_) => return, // Mock state: error response, skip body assertions
    };

    // Trace data should be present (for registry path)
    // Note: Demo mode doesn't have trace support in the same way
}

#[tokio::test]
async fn test_openai_chat_completions_with_trace_header_step() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "default",
        "messages": [{"role": "user", "content": "Hi"}]
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .header("X-Trace-Level", "step")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert!(
        response.status() == StatusCode::OK
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
}

#[tokio::test]
async fn test_openai_chat_completions_with_trace_header_layer() {
    let app = create_test_app_shared();

    let req_body = serde_json::json!({
        "model": "default",
        "messages": [{"role": "user", "content": "Hi"}]
    });

    let response = app
        .oneshot(
            Request::builder()
                .method("POST")
                .uri("/v1/chat/completions")
                .header("content-type", "application/json")
                .header("X-Trace-Level", "layer")
                .body(Body::from(serde_json::to_string(&req_body).unwrap()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert!(
        response.status() == StatusCode::OK
            || response.status() == StatusCode::NOT_FOUND
            || response.status() == StatusCode::INTERNAL_SERVER_ERROR
            || response.status() == StatusCode::SERVICE_UNAVAILABLE
            || response.status() == StatusCode::UNPROCESSABLE_ENTITY
    );
}

// =============================================================================
// Error Response Tests
// =============================================================================

#[test]
fn test_error_response_serialization() {
    let error = ErrorResponse {
        error: "Something went wrong".to_string(),
    };

    let json = serde_json::to_string(&error).expect("serialize");
    assert!(json.contains("Something went wrong"));

    let parsed: ErrorResponse = serde_json::from_str(&json).expect("deserialize");
    assert_eq!(parsed.error, "Something went wrong");
}

// =============================================================================
// Edge Cases and Boundary Tests
// =============================================================================

#[test]
fn test_chat_completion_request_max_tokens_zero() {
    let json = r#"{
        "model": "test",
        "messages": [{"role": "user", "content": "Hi"}],
        "max_tokens": 0
    }"#;
    let req: ChatCompletionRequest = serde_json::from_str(json).expect("deserialize");
    assert_eq!(req.max_tokens, Some(0));
}

#[test]
fn test_chat_completion_request_temperature_extremes() {
    // Temperature = 0 (greedy)
    let json_zero = r#"{
        "model": "test",
        "messages": [{"role": "user", "content": "Hi"}],
        "temperature": 0.0
    }"#;
    let req_zero: ChatCompletionRequest = serde_json::from_str(json_zero).expect("deserialize");
    assert_eq!(req_zero.temperature, Some(0.0));

    // Temperature = 2 (very random)
    let json_high = r#"{
        "model": "test",
        "messages": [{"role": "user", "content": "Hi"}],
        "temperature": 2.0
    }"#;
    let req_high: ChatCompletionRequest = serde_json::from_str(json_high).expect("deserialize");
    assert_eq!(req_high.temperature, Some(2.0));
}

#[test]
fn test_chat_message_empty_content() {
    let msg = ChatMessage {
        role: "user".to_string(),
        content: String::new(),
        name: None,
    };

    let json = serde_json::to_string(&msg).expect("serialize");
    assert!(json.contains("\"content\":\"\""));
}

#[test]
fn test_chat_message_unicode_content() {
    let msg = ChatMessage {
        role: "user".to_string(),
        content: "Hello ‰∏ñÁïå! üåç ŸÖÿ±ÿ≠ÿ®ÿß".to_string(),
        name: None,
    };

    let json = serde_json::to_string(&msg).expect("serialize");
    let parsed: ChatMessage = serde_json::from_str(&json).expect("deserialize");
    assert_eq!(parsed.content, "Hello ‰∏ñÁïå! üåç ŸÖÿ±ÿ≠ÿ®ÿß");
}

#[test]
fn test_chat_message_special_characters() {
    let msg = ChatMessage {
        role: "user".to_string(),
        content: "Test with \"quotes\" and \\backslashes\\ and\nnewlines".to_string(),
        name: None,
    };

    let json = serde_json::to_string(&msg).expect("serialize");
    let parsed: ChatMessage = serde_json::from_str(&json).expect("deserialize");
    assert!(parsed.content.contains("quotes"));
    assert!(parsed.content.contains("\\"));
    assert!(parsed.content.contains("\n"));
}

#[test]
fn test_usage_zero_values() {
    let usage = Usage {
        prompt_tokens: 0,
        completion_tokens: 0,
        total_tokens: 0,
    };

    let json = serde_json::to_string(&usage).expect("serialize");
    let parsed: Usage = serde_json::from_str(&json).expect("deserialize");
    assert_eq!(parsed.total_tokens, 0);
}

#[test]
fn test_usage_large_values() {
    let usage = Usage {
        prompt_tokens: 1_000_000,
        completion_tokens: 500_000,
        total_tokens: 1_500_000,
    };

    let json = serde_json::to_string(&usage).expect("serialize");
    let parsed: Usage = serde_json::from_str(&json).expect("deserialize");
    assert_eq!(parsed.total_tokens, 1_500_000);
}
